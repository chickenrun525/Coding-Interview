1. Where is cache? memory
2. What are popular cache tools/server? Memcached and Redis
3. Systems for message queue: Redis, Kafka, ZeroMQ, RabbitMQ
4. Based on experience, QPS 100 pc, 1K web server, 1M cluster of web servers. One web server 1K, 1 SQL/PosgreSQL server 1K QPS, 1 NoSQL Cassandra, 10K, 1 NoSQL memcached 1M QPS
5. System (read intensive but not write intensive): must cache. Memcached: non-persistent; Redis: persistent.
6. Cache could be in not only server, but also browser/client/frontend.
7. Session key is generated when user log into the system. Then session key is stored in cookie and every time user sends something to some web server, check if session_key is still valid.
8. Session table is on the server side, either in cache or in DB. when generated, send this user a session_key by cookie. Session is stored at web server frontend. Cookie is stored at browser end.
9. Based on how much visited requirement, decide to store in cache or DB.
10. Redis: cache_through, memcached: cache_aside. How to understand them and their difference?
11. MySQL, SQL, NoSQL, PosgreSQL difference? Why transaction is not NoSQL? Not ACID.
12. Cassandra based query: support 2 layer index query (row key, column key). Col key can be range query.
13. SQL column is fixed and cannot be added or deleted (fixed by Schema); NoSQL column is dynamic and can be infinite, so needs col index or range.
14. Based on 12 and 13, for friendship table, SQL will either stores A->B or A,B pair, but NoSQL can store dynamically
15. User table is usually stored in SQL/MySQL for reliability and secondary index, friendship table is in NoSQL table.
16. SQL no sharding, needs manual split. NoSQL has auto sharding.
17. Vertical sharding: split different tables into different servers, horizontal sharding: just expanding to different machines.
18. horizontal sharding: needs to choose consistent hasing because if not, data migration is costy.
19. MapReduce: Reduce machine upper limit is the number of keys. Because in this model, only one layer of reducers. So no more reducers for reducers.
20. MapReduce: between mapper and reducer, sort outside harddrive and k-merge between them (Partition sort and merge sort). Global input ouput files are stored in GFS. Mapper output files are stored in local machines.
21. Master-Slave pattern for DB: M: store the data; S: backup;  for FS: M: organizer (metadata); S: stores the data
22. GFS master only stores metadata, which files stored on which slave server, no need the offset on that slave server. Each slave server stores a index table. ----> Reduce communication between master and slave.
23. When write to GFS, master tell client where to write, clients write to slave by themselves. Strategy to select slave to write: LRU/largest volume. Strategy to select the first slave: nearest/least traffic.
24. When write to DB as into FS, sort inside RAM first, then write to DB. Just append, no revise, with write log ahead. Index used for quickly find the data inside the file.
25. To find some record, get row key from key, find the corresponding server by row key, skip list to find in RAM, Bloom filter+index to find in DB.
26. Bigtable and GFS both uses mater-slave model, write to Bigtable tablet server first, then move to GFS server.
27. Tablet server just stores the write requirement in RAM and log then push to GFS. Lock server takes care of metadata, master kind of useless (shard the data and manage servers health).
28. General question: what if server break down? Back up server + log as recovery, some devices also haves logs on device, once connection is set up, recover from devices
29. Cassandra is very good for wide-column based database, say, Instagram, recording which user stores which pictures.
30. Pull vs push model: pull model will not see the latest happening until the user issues the request, and most of the time pull model gives empty back. Push model is not good for popular users, JB, Gaga.
31. A modern server can hold 4TB storage and 144 GB RAM.
32. Proxy layer can be added between clients and web server as serving both as LB and caching.
33. NoSQL: document based: MongoDB, wide-column based: Cassandra or HBase, Key-value based: Redis. Mostly will choose SQL for ACID, all the rest goes to NoSQL.
34. Three places to add LB: between users and web servers, between web servers and app/cache servers, between internal APP servers and DB
35. LB should be able to monitor the hardware workload and make adjustment based on current situation, some strategy like RR, random, random with weight.
36. Whenever deals with large files(YouTube videos, Instagram photos), need metadata server (metadata DB) and processing queue for process. For files, memcache is good for caching, no need Redis in this case.
37. If you shard the data based on auto-increment value, they when do the query, always needs an aggregator to count the total appearance from every servers.
